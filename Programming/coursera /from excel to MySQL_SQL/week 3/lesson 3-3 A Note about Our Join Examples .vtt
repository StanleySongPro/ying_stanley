WEBVTT

1
00:00:04.790 --> 00:00:06.410
Hi again.

2
00:00:06.410 --> 00:00:08.580
I bet you're really excited
to start joining some tables.

3
00:00:08.580 --> 00:00:09.970
And I'm excited for you too.

4
00:00:09.970 --> 00:00:12.590
I think you're really going to
enjoy it and it's going to be fun.

5
00:00:12.590 --> 00:00:16.090
But I did want to tell you
something before you keep going.

6
00:00:16.090 --> 00:00:18.630
I wanted to let you know that some
of the examples I just showed you in

7
00:00:18.630 --> 00:00:19.410
the past two videos and

8
00:00:19.410 --> 00:00:23.450
some of the example you're going to use in
the rest of this course are not standard.

9
00:00:23.450 --> 00:00:25.820
You're not going to see them
nescule textbook for example.

10
00:00:25.820 --> 00:00:28.240
And the thing that's
not standard about them

11
00:00:28.240 --> 00:00:31.930
is that I showed you examples that have
null values and duplicate rows and

12
00:00:31.930 --> 00:00:35.100
columns that are supposed to be
used to link tables together.

13
00:00:35.100 --> 00:00:37.590
In theory that should be impossible but

14
00:00:37.590 --> 00:00:40.060
certainly violates the concepts
of set theory for example.

15
00:00:40.060 --> 00:00:42.690
Which says that there shouldn't
be any duplicate rows and

16
00:00:42.690 --> 00:00:47.240
if you declare a column to be a primary
key in a database it usually prevents you

17
00:00:47.240 --> 00:00:50.830
from having any duplicate rows and it
prevents you from having any null values.

18
00:00:50.830 --> 00:00:53.150
So why did I use those examples?

19
00:00:53.150 --> 00:00:56.940
I used those examples because that's
what can happen in real life.

20
00:00:56.940 --> 00:00:59.990
Sometimes companies need to collect
data faster than having the perfect

21
00:00:59.990 --> 00:01:01.590
database will allow.

22
00:01:01.590 --> 00:01:04.300
Sometimes it's more important
to have some imperfect data

23
00:01:04.300 --> 00:01:06.470
than to have no perfect data.

24
00:01:06.470 --> 00:01:08.980
This happens a lot in
startups in particular.

25
00:01:08.980 --> 00:01:12.320
Sometimes they don't want to declare
a column to be a primary key

26
00:01:12.320 --> 00:01:14.890
because they can't risk not
collecting any data at all.

27
00:01:14.890 --> 00:01:18.290
It's too early in the company, and they
need to make sure they have something.

28
00:01:18.290 --> 00:01:21.500
When this happens,
usually they fix any problems and

29
00:01:21.500 --> 00:01:26.050
there's so little bad data that there's no
incentive to fix the database immediately.

30
00:01:26.050 --> 00:01:28.410
They have other things to worry about.

31
00:01:28.410 --> 00:01:31.250
I wanted to make sure you knew how
to handle these types of situations.

32
00:01:31.250 --> 00:01:34.740
We're going to see it in our
dognition data set, for example.

33
00:01:34.740 --> 00:01:39.250
It looks like at the very beginning
they might have had some issues,

34
00:01:39.250 --> 00:01:43.110
when they were testing and so
some null values and some primary, or

35
00:01:43.110 --> 00:01:47.110
some duplicate rows snuck in because they
didn't declare a column as a primary key.

36
00:01:47.110 --> 00:01:49.196
This is a very small part
of the database and is so

37
00:01:49.196 --> 00:01:51.550
it usually doesn't affect your analysis.

38
00:01:51.550 --> 00:01:55.510
Where it will affect analysis is in these
edge cases when you're doing these outer

39
00:01:55.510 --> 00:02:00.440
joins that end up being impacted
by these duplicate rows and

40
00:02:00.440 --> 00:02:03.820
by these null values because they
have multiplicative effects.

41
00:02:03.820 --> 00:02:07.260
As a data analyst it is not your
job to make a perfect database.

42
00:02:07.260 --> 00:02:10.090
In fact you're usually not making
a database in the first place.

43
00:02:10.090 --> 00:02:13.860
What it is your job to do is to create
value out of whatever data a company has

44
00:02:13.860 --> 00:02:15.350
stored in any type of database.

45
00:02:16.400 --> 00:02:17.840
I wanted to make sure you could do that.

46
00:02:19.060 --> 00:02:21.930
That's why I didn't clean up
the dubmission data set to make it look

47
00:02:21.930 --> 00:02:22.730
like a textbook.

48
00:02:22.730 --> 00:02:26.080
I didn't take out the null values and
I didn't take out the duplicate rows.

49
00:02:26.080 --> 00:02:29.720
You might want to do that if you're an
analyst in that company and you had time.

50
00:02:29.720 --> 00:02:31.815
But I wanted to make sure you
knew what to do about it.

51
00:02:32.835 --> 00:02:35.625
And when by learning how,
what to do with these edge cases,

52
00:02:35.625 --> 00:02:38.555
I do believe that it will help you
really understand how joints work.

53
00:02:38.555 --> 00:02:41.095
Which will make it much easier for
you to use the standard

54
00:02:41.095 --> 00:02:44.935
scenarios where data look pristine and
there are no problems.

55
00:02:44.935 --> 00:02:47.765
So I hope you will enjoy this
opportunity to use real data

56
00:02:47.765 --> 00:02:48.765
rather than textbook data.

57
00:02:49.795 --> 00:02:52.905
With that, go become join masters.